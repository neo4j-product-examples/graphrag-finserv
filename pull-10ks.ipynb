{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pull 10k Filings\n",
    "Based off Sample mappings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:25:19.878876Z",
     "start_time": "2024-06-16T22:25:18.972851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "%pip install python-dotenv pandas tqdm lxml"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "pd.set_option('display.width', 0)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.max_rows', 50)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T22:25:27.657Z",
     "start_time": "2024-06-16T22:25:27.088360Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "## Get and Save 10k URLs",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "map_df = pd.read_csv('cik-cusip-sample-map.csv')\n",
    "map_df.cik = map_df.cik.astype(int)\n",
    "map_df.sort_values(by='cusip6')\n",
    "map_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T22:25:29.185337Z",
     "start_time": "2024-06-16T22:25:28.985091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      cusip6      cik  \\\n",
       "0     001055     4977   \n",
       "1     001084  1100441   \n",
       "2     001228  1514281   \n",
       "3     00123Q  1423689   \n",
       "4     00130H   874761   \n",
       "...      ...      ...   \n",
       "4643  Y81669  1328919   \n",
       "4644  Y8564W   911971   \n",
       "4645  Y8565N  1419945   \n",
       "4646  Y8897Y  1296484   \n",
       "4647  Y95308  1631574   \n",
       "\n",
       "                                                                        name  \\\n",
       "0                                                              {'AFLAC INC'}   \n",
       "1                                                              {'AGCO CORP'}   \n",
       "2                                           {'AG MORTGAGE INVESTMENT TRUST'}   \n",
       "3                                {'AGNC INVT CORP', 'AGNC Investment Corp.'}   \n",
       "4                                                               {'AES CORP'}   \n",
       "...                                                                      ...   \n",
       "4643                                                      {'STEALTHGAS INC'}   \n",
       "4644                                    {'TEEKAY CORPORATION', 'Teekay Inc'}   \n",
       "4645  {'TEEKAY TANKERS LTD', 'Teekay Tankers', 'TEEKAY TANKERS LTD-CLASS A'}   \n",
       "4646                                                       {'TOP SHIPS INC'}   \n",
       "4647                                              {'WAVE LIFE SCIENCES LTD'}   \n",
       "\n",
       "                                                                  cusip  \n",
       "0                  {'001055102', '001055952', '000105510', '001055902'}  \n",
       "1                               {'001084952', '001084902', '001084102'}  \n",
       "2                                                         {'001228501'}  \n",
       "3                  {'00123q104', '00123Q104', '00123Q954', '00123Q904'}  \n",
       "4                  {'00130H905', '00130H955', '00130H105', '00130h105'}  \n",
       "...                                                                 ...  \n",
       "4643                                                      {'Y81669106'}  \n",
       "4644               {'Y8564W103', 'y8564w103', 'Y8564W903', 'Y8564W953'}  \n",
       "4645  {'Y8565N900', 'y8565n102', 'Y8565N300', 'y8565n300', 'Y8565N950'}  \n",
       "4646                                                      {'y8897y198'}  \n",
       "4647                                                      {'Y95308105'}  \n",
       "\n",
       "[4648 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip6</th>\n",
       "      <th>cik</th>\n",
       "      <th>name</th>\n",
       "      <th>cusip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001055</td>\n",
       "      <td>4977</td>\n",
       "      <td>{'AFLAC INC'}</td>\n",
       "      <td>{'001055102', '001055952', '000105510', '001055902'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001084</td>\n",
       "      <td>1100441</td>\n",
       "      <td>{'AGCO CORP'}</td>\n",
       "      <td>{'001084952', '001084902', '001084102'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001228</td>\n",
       "      <td>1514281</td>\n",
       "      <td>{'AG MORTGAGE INVESTMENT TRUST'}</td>\n",
       "      <td>{'001228501'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00123Q</td>\n",
       "      <td>1423689</td>\n",
       "      <td>{'AGNC INVT CORP', 'AGNC Investment Corp.'}</td>\n",
       "      <td>{'00123q104', '00123Q104', '00123Q954', '00123Q904'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00130H</td>\n",
       "      <td>874761</td>\n",
       "      <td>{'AES CORP'}</td>\n",
       "      <td>{'00130H905', '00130H955', '00130H105', '00130h105'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>Y81669</td>\n",
       "      <td>1328919</td>\n",
       "      <td>{'STEALTHGAS INC'}</td>\n",
       "      <td>{'Y81669106'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>Y8564W</td>\n",
       "      <td>911971</td>\n",
       "      <td>{'TEEKAY CORPORATION', 'Teekay Inc'}</td>\n",
       "      <td>{'Y8564W103', 'y8564w103', 'Y8564W903', 'Y8564W953'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>Y8565N</td>\n",
       "      <td>1419945</td>\n",
       "      <td>{'TEEKAY TANKERS LTD', 'Teekay Tankers', 'TEEKAY TANKERS LTD-CLASS A'}</td>\n",
       "      <td>{'Y8565N900', 'y8565n102', 'Y8565N300', 'y8565n300', 'Y8565N950'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>Y8897Y</td>\n",
       "      <td>1296484</td>\n",
       "      <td>{'TOP SHIPS INC'}</td>\n",
       "      <td>{'y8897y198'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>Y95308</td>\n",
       "      <td>1631574</td>\n",
       "      <td>{'WAVE LIFE SCIENCES LTD'}</td>\n",
       "      <td>{'Y95308105'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4648 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:25:33.001613Z",
     "start_time": "2024-06-16T22:25:32.988276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from typing import Dict, Tuple, List\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import http.client\n",
    "\n",
    "BASE_URL = 'https://www.sec.gov'\n",
    "\n",
    "def create_urls_df(cusip_df: pd.DataFrame,\n",
    "                   dates_from_to:Tuple[str,str] = ('2023-01-01', '2024-01-01'),\n",
    "                   user_email:str='sales@neo4j.com',\n",
    "                   user_name='Neo4j') -> pd.DataFrame:\n",
    "    \n",
    "    print(f'Found {cusip_df.shape[0]:,} companies to pull filings for')\n",
    "    start_date = datetime.strptime(dates_from_to[0], '%Y-%m-%d').date()\n",
    "    end_date = datetime.strptime(dates_from_to[1], '%Y-%m-%d').date()\n",
    "\n",
    "    urls_list = []\n",
    "\n",
    "    counter = 0\n",
    "    for ind, row in tqdm(cusip_df.iterrows()):\n",
    "        #counter += 1\n",
    "        #print(f'pulling 10k urls for cusip6: {row.cusip6}, {counter} of {map_df.shape[0]} cusips')\n",
    "        urls = get_urls(row.cik, start_date, end_date, f'{user_name} {user_email}')\n",
    "        #print(f'{row.cik}: {urls}')\n",
    "        urls_list.append(urls)\n",
    "\n",
    "    cusip_df['form10KUrls'] = urls_list\n",
    "    return cusip_df[cusip_df.form10KUrls.map(len) > 0].explode(column='form10KUrls')\n",
    "\n",
    "\n",
    "def get_urls(cik: str, start_date: datetime.date, end_date: datetime.date, user_agent: str):\n",
    "    filing_accessors = get_filing_accessors(cik, start_date, end_date, user_agent)\n",
    "    return [format_url(cik, f) for f in filing_accessors]\n",
    "\n",
    "\n",
    "def get_filing_accessors(cik: str, start_date: datetime.date, end_date: datetime.date, user_agent: str) -> List[str]:\n",
    "    history = get_filing_history(cik, user_agent)\n",
    "    history_df = pd.DataFrame.from_dict(history['filings']['recent'])\n",
    "    history_df.filingDate = pd.to_datetime(history_df.filingDate).dt.date\n",
    "    filtered_df = history_df[(history_df.filingDate <= end_date) &\n",
    "                             (history_df.filingDate >= start_date) &\n",
    "                             (history_df.form == '10-K')]\n",
    "    return filtered_df.accessionNumber.tolist()\n",
    "\n",
    "\n",
    "def get_filing_history(cik: str, user_agent: str) -> Dict:\n",
    "    url = f'https://data.sec.gov//submissions/CIK{int(cik):010d}.json'\n",
    "    #print(f'Downloading filing history for cik: {cik}')\n",
    "    conn = http.client.HTTPSConnection('www.sec.gov')\n",
    "    conn.request('GET', url, headers={'User-Agent': user_agent})\n",
    "    response = conn.getresponse()\n",
    "    #print(response.status, response.reason)\n",
    "    data = response.read()\n",
    "    conn.close()\n",
    "\n",
    "    if response.status == 200 and response.reason == 'OK':\n",
    "        res = data.decode('utf-8')\n",
    "        return json.loads(res)\n",
    "    else:\n",
    "        print(f'Download failed for cik: {cik} filings.')\n",
    "    return dict()\n",
    "\n",
    "\n",
    "def format_url(cik: str, filing_accessor: str):\n",
    "    return BASE_URL + f'/Archives/edgar/data/{int(cik)}/{filing_accessor.replace(\"-\", \"\")}/{filing_accessor}.txt'\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:53:57.570391Z",
     "start_time": "2024-06-16T21:53:56.644896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ddf = map_df[:3].reset_index(drop=True)\n",
    "create_urls_df(ddf)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 companies to pull filings for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  3.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   cusip6      cik                              name  \\\n",
       "0  001055     4977                     {'AFLAC INC'}   \n",
       "2  001228  1514281  {'AG MORTGAGE INVESTMENT TRUST'}   \n",
       "\n",
       "                                                  cusip  \\\n",
       "0  {'001055102', '001055952', '000105510', '001055902'}   \n",
       "2                                         {'001228501'}   \n",
       "\n",
       "                                                                                   form10KUrls  \n",
       "0     https://www.sec.gov/Archives/edgar/data/4977/000000497723000055/0000004977-23-000055.txt  \n",
       "2  https://www.sec.gov/Archives/edgar/data/1514281/000151428123000020/0001514281-23-000020.txt  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip6</th>\n",
       "      <th>cik</th>\n",
       "      <th>name</th>\n",
       "      <th>cusip</th>\n",
       "      <th>form10KUrls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001055</td>\n",
       "      <td>4977</td>\n",
       "      <td>{'AFLAC INC'}</td>\n",
       "      <td>{'001055102', '001055952', '000105510', '001055902'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/4977/000000497723000055/0000004977-23-000055.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001228</td>\n",
       "      <td>1514281</td>\n",
       "      <td>{'AG MORTGAGE INVESTMENT TRUST'}</td>\n",
       "      <td>{'001228501'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1514281/000151428123000020/0001514281-23-000020.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:18:27.056073Z",
     "start_time": "2024-06-16T21:54:46.246840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "urls_df = create_urls_df(map_df)\n",
    "urls_df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4,648 companies to pull filings for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4648it [23:40,  3.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      cusip6      cik  \\\n",
       "0     001055     4977   \n",
       "2     001228  1514281   \n",
       "3     00123Q  1423689   \n",
       "4     00130H   874761   \n",
       "6     00164V  1514991   \n",
       "...      ...      ...   \n",
       "4624  Y2187A  1322439   \n",
       "4626  Y2573F   866374   \n",
       "4627  Y2685T  1326200   \n",
       "4632  Y41053  1679049   \n",
       "4647  Y95308  1631574   \n",
       "\n",
       "                                                                                                   name  \\\n",
       "0                                                                                         {'AFLAC INC'}   \n",
       "2                                                                      {'AG MORTGAGE INVESTMENT TRUST'}   \n",
       "3                                                           {'AGNC INVT CORP', 'AGNC Investment Corp.'}   \n",
       "4                                                                                          {'AES CORP'}   \n",
       "6                                                            {'AMC NETWORKS INC', 'AMC NETWORKS INC A'}   \n",
       "...                                                                                                 ...   \n",
       "4624                                                                        {'EAGLE BULK SHIPPING INC'}   \n",
       "4626                                                                           {'Flex Ltd', 'FLEX LTD'}   \n",
       "4627  {'GENCO SHIPPING AND TRADING LIM', 'GENCO SHIPPING & TRADING LTD', 'GENCO SHIPPING  TRADING LTD'}   \n",
       "4632                                                                      {'INTERNATIONAL SEAWAYS INC'}   \n",
       "4647                                                                         {'WAVE LIFE SCIENCES LTD'}   \n",
       "\n",
       "                                                     cusip  \\\n",
       "0     {'001055102', '001055952', '000105510', '001055902'}   \n",
       "2                                            {'001228501'}   \n",
       "3     {'00123q104', '00123Q104', '00123Q954', '00123Q904'}   \n",
       "4     {'00130H905', '00130H955', '00130H105', '00130h105'}   \n",
       "6                  {'00164V103', '00164V903', '00164V953'}   \n",
       "...                                                    ...   \n",
       "4624  {'y2187a150', 'Y2187A150', 'Y2187A900', 'Y2187A950'}   \n",
       "4626  {'y2573f102', 'Y2573F102', 'Y2573F902', 'Y2573F952'}   \n",
       "4627  {'Y2685T131', 'Y2685T901', 'Y2685T951', 'y2685t131'}   \n",
       "4632               {'Y41053952', 'Y41053102', 'Y41053902'}   \n",
       "4647                                         {'Y95308105'}   \n",
       "\n",
       "                                                                                      form10KUrls  \n",
       "0        https://www.sec.gov/Archives/edgar/data/4977/000000497723000055/0000004977-23-000055.txt  \n",
       "2     https://www.sec.gov/Archives/edgar/data/1514281/000151428123000020/0001514281-23-000020.txt  \n",
       "3     https://www.sec.gov/Archives/edgar/data/1423689/000142368923000017/0001423689-23-000017.txt  \n",
       "4      https://www.sec.gov/Archives/edgar/data/874761/000087476123000010/0000874761-23-000010.txt  \n",
       "6     https://www.sec.gov/Archives/edgar/data/1514991/000151499123000009/0001514991-23-000009.txt  \n",
       "...                                                                                           ...  \n",
       "4624  https://www.sec.gov/Archives/edgar/data/1322439/000162828023007526/0001628280-23-007526.txt  \n",
       "4626   https://www.sec.gov/Archives/edgar/data/866374/000086637423000028/0000866374-23-000028.txt  \n",
       "4627  https://www.sec.gov/Archives/edgar/data/1326200/000155837023001781/0001558370-23-001781.txt  \n",
       "4632  https://www.sec.gov/Archives/edgar/data/1679049/000155837023002247/0001558370-23-002247.txt  \n",
       "4647  https://www.sec.gov/Archives/edgar/data/1631574/000095017023009319/0000950170-23-009319.txt  \n",
       "\n",
       "[3365 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip6</th>\n",
       "      <th>cik</th>\n",
       "      <th>name</th>\n",
       "      <th>cusip</th>\n",
       "      <th>form10KUrls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001055</td>\n",
       "      <td>4977</td>\n",
       "      <td>{'AFLAC INC'}</td>\n",
       "      <td>{'001055102', '001055952', '000105510', '001055902'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/4977/000000497723000055/0000004977-23-000055.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001228</td>\n",
       "      <td>1514281</td>\n",
       "      <td>{'AG MORTGAGE INVESTMENT TRUST'}</td>\n",
       "      <td>{'001228501'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1514281/000151428123000020/0001514281-23-000020.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00123Q</td>\n",
       "      <td>1423689</td>\n",
       "      <td>{'AGNC INVT CORP', 'AGNC Investment Corp.'}</td>\n",
       "      <td>{'00123q104', '00123Q104', '00123Q954', '00123Q904'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1423689/000142368923000017/0001423689-23-000017.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00130H</td>\n",
       "      <td>874761</td>\n",
       "      <td>{'AES CORP'}</td>\n",
       "      <td>{'00130H905', '00130H955', '00130H105', '00130h105'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/874761/000087476123000010/0000874761-23-000010.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00164V</td>\n",
       "      <td>1514991</td>\n",
       "      <td>{'AMC NETWORKS INC', 'AMC NETWORKS INC A'}</td>\n",
       "      <td>{'00164V103', '00164V903', '00164V953'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1514991/000151499123000009/0001514991-23-000009.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>Y2187A</td>\n",
       "      <td>1322439</td>\n",
       "      <td>{'EAGLE BULK SHIPPING INC'}</td>\n",
       "      <td>{'y2187a150', 'Y2187A150', 'Y2187A900', 'Y2187A950'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1322439/000162828023007526/0001628280-23-007526.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>Y2573F</td>\n",
       "      <td>866374</td>\n",
       "      <td>{'Flex Ltd', 'FLEX LTD'}</td>\n",
       "      <td>{'y2573f102', 'Y2573F102', 'Y2573F902', 'Y2573F952'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/866374/000086637423000028/0000866374-23-000028.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>Y2685T</td>\n",
       "      <td>1326200</td>\n",
       "      <td>{'GENCO SHIPPING AND TRADING LIM', 'GENCO SHIPPING &amp; TRADING LTD', 'GENCO SHIPPING  TRADING LTD'}</td>\n",
       "      <td>{'Y2685T131', 'Y2685T901', 'Y2685T951', 'y2685t131'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1326200/000155837023001781/0001558370-23-001781.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>Y41053</td>\n",
       "      <td>1679049</td>\n",
       "      <td>{'INTERNATIONAL SEAWAYS INC'}</td>\n",
       "      <td>{'Y41053952', 'Y41053102', 'Y41053902'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1679049/000155837023002247/0001558370-23-002247.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>Y95308</td>\n",
       "      <td>1631574</td>\n",
       "      <td>{'WAVE LIFE SCIENCES LTD'}</td>\n",
       "      <td>{'Y95308105'}</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/1631574/000095017023009319/0000950170-23-009319.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3365 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:18:36.984907Z",
     "start_time": "2024-06-16T22:18:36.970192Z"
    }
   },
   "cell_type": "code",
   "source": "urls_df.to_csv('f10k-urls-map.csv', index=False)",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download, Parse, and Format 10k Forms"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:26:12.314820Z",
     "start_time": "2024-06-16T22:26:12.297857Z"
    }
   },
   "cell_type": "code",
   "source": "urls_df = pd.read_csv('f10k-urls-map.csv')",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:26:16.765213Z",
     "start_time": "2024-06-16T22:26:16.678343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def make_10k_jsons(url_df:pd.DataFrame,\n",
    "                   temp_dir:str='data/form10k',\n",
    "                   output_dir:str='data/form10k-clean',\n",
    "                   user_email:str='sales@neo4j.com',\n",
    "                   user_name='Neo4j') -> int:\n",
    "\n",
    "\n",
    "    print(f'Found {url_df.shape[0]:,} companies to pull filings for')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    count = 0\n",
    "    total = url_df.shape[0]\n",
    "    print(f'=== Downloading {total:,} 10K filings ===')\n",
    "    for ind, row in url_df.iterrows():\n",
    "        count += 1\n",
    "        print(f'--- Downloading {count:,} of {total:,} 10K filings for {row.name}')\n",
    "        raw_file_path, file_id = download_filing(row.form10KUrls, f'{user_name} {user_email}', temp_dir)\n",
    "        if len(raw_file_path) > 0:\n",
    "            output_file_path = os.path.join(output_dir, file_id + '.json')\n",
    "            try:\n",
    "                load_parse_save(raw_file_path, output_file_path, row.cik, row.cusip6, row.form10KUrls)\n",
    "                os.remove(raw_file_path)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def download_filing(url: str, user_agent: str, temp_dir: str) -> tuple:\n",
    "    conn = http.client.HTTPSConnection('www.sec.gov')\n",
    "    conn.request('GET', url, headers={'User-Agent': user_agent})\n",
    "    response = conn.getresponse()\n",
    "    data = response.read()\n",
    "    conn.close()\n",
    "\n",
    "    if response.status == 200 and response.reason == 'OK':\n",
    "        text = data.decode('utf-8')\n",
    "        file = io.StringIO(text)\n",
    "        contents = file.read()\n",
    "        file.close()\n",
    "        file_id = url[url.rindex('/') + 1:url.rindex('.')]\n",
    "        file_path = os.path.join(temp_dir, 'raw_' + file_id + '.txt')\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(contents)\n",
    "        return file_path, file_id\n",
    "    else:\n",
    "        print('Download failed for form13 file.')\n",
    "        print(response.status, response.reason)\n",
    "        return '', ''\n",
    "\n",
    "\n",
    "def extract_10_k(txt: str) -> str:\n",
    "    # Regex to find <DOCUMENT> tags\n",
    "    doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "    doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
    "    # Regex to find <TYPE> tag proceeding any characters, terminating at new line\n",
    "    type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
    "    # Create 3 lists with the span idices for each regex\n",
    "\n",
    "    # There are many <Document> Tags in this text file, each as specific exhibit like 10-K, EX-10.17 etc\n",
    "    # First filter will give us document tag start <end> and document tag end's <start>\n",
    "    # We will use this to later grab content in between these tags\n",
    "    doc_start_is = [x.end() for x in doc_start_pattern.finditer(txt)]\n",
    "    doc_end_is = [x.start() for x in doc_end_pattern.finditer(txt)]\n",
    "\n",
    "    # Type filter is interesting, it looks for <TYPE> with Not flag as new line, ie terminare there, with + sign\n",
    "    # to look for any char afterwards until new line \\n. This will give us <TYPE> followed Section Name like '10-K'\n",
    "    # Once we have this, it returns String Array, below line will with find content after <TYPE> ie, '10-K'\n",
    "    # as section names\n",
    "    doc_types = [x[len('<TYPE>'):] for x in type_pattern.findall(txt)]\n",
    "    # Create a loop to go through each section type and save only the 10-K section in the dictionary\n",
    "    # there is just one 10-K section\n",
    "    for doc_type, doc_start, doc_end in zip(doc_types, doc_start_is, doc_end_is):\n",
    "        if doc_type == '10-K':\n",
    "            return txt[doc_start:doc_end]\n",
    "\n",
    "\n",
    "# Extract text using position dataframe and beautiful soup\n",
    "def beautify_text(txt: str) -> str:\n",
    "    stg_txt = BeautifulSoup(txt, 'lxml')\n",
    "    return stg_txt.get_text('\\n')\n",
    "\n",
    "\n",
    "def extract_text(row: pd.Series, txt: str):\n",
    "    section_txt = txt[row.start:row.sectionEnd].replace('Error! Bookmark not defined.', '')\n",
    "    return beautify_text(section_txt)\n",
    "\n",
    "\n",
    "def extract_section_text(doc: str) -> Dict[str, str]:\n",
    "    # Write the regex\n",
    "    regex = re.compile(r'(>(Item|ITEM)(\\s|&#160;|&nbsp;)(1A|1B|1\\.|7A|7|8)\\.{0,1})|(ITEM\\s(1A|1B|1\\.|7A|7|8))')\n",
    "    # Use finditer to math the regex\n",
    "    matches = regex.finditer(doc)\n",
    "    # Write a for loop to print the matches\n",
    "    # Create the dataframe\n",
    "    item_df = pd.DataFrame([(x.group(), x.start(), x.end()) for x in matches])\n",
    "    item_df.columns = ['item', 'start', 'end']\n",
    "    item_df['item'] = item_df.item.str.lower()\n",
    "\n",
    "    item_df.replace('&#160;', ' ', regex=True, inplace=True)\n",
    "    item_df.replace('&nbsp;', ' ', regex=True, inplace=True)\n",
    "    item_df.replace(' ', '', regex=True, inplace=True)\n",
    "    item_df.replace('\\.', '', regex=True, inplace=True)\n",
    "    item_df.replace('>', '', regex=True, inplace=True)\n",
    "\n",
    "    all_pos_df = item_df.sort_values('start', ascending=True).drop_duplicates(subset=['item'], keep='last').set_index(\n",
    "        'item')\n",
    "    # Add section end using start of next section\n",
    "    all_pos_df['sectionEnd'] = all_pos_df.start.iloc[1:].tolist() + [len(doc)]\n",
    "    # filter to just the sections we care about\n",
    "    pos_df = all_pos_df.loc[['item1', 'item1a', 'item7', 'item7a'], :]\n",
    "    res = dict()\n",
    "    for i, row in pos_df.iterrows():\n",
    "        res[i] = extract_text(row, doc)\n",
    "    return res\n",
    "\n",
    "\n",
    "def load_parse_save(input_file_path: str, output_file_path: str, cik: str, cusip6: str, url: str):\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        raw_txt = file.read()\n",
    "    print('Extracting 10-K')\n",
    "    doc = extract_10_k(raw_txt)\n",
    "    print('Parsing relevant sections')\n",
    "    cleaned_json_txt = extract_section_text(doc)\n",
    "    cleaned_json_txt['cik'] = cik\n",
    "    cleaned_json_txt['cusip6'] = cusip6\n",
    "    cleaned_json_txt['source'] = url[:url.rindex('.')] + '-index.htm'\n",
    "    print('Writing clean text to json')\n",
    "    with open(output_file_path, 'w') as json_file:\n",
    "        json.dump(cleaned_json_txt, json_file, indent=4)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:26:21.884431Z",
     "start_time": "2024-06-16T22:26:17.648474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url_samp_df = urls_df[:3]\n",
    "make_10k_jsons(url_samp_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 companies to pull filings for\n",
      "=== Downloading 3 10K filings ===\n",
      "--- Downloading 1 of 3 10K filings for 0\n",
      "Extracting 10-K\n",
      "Parsing relevant sections\n",
      "Writing clean text to json\n",
      "--- Downloading 2 of 3 10K filings for 1\n",
      "Extracting 10-K\n",
      "Parsing relevant sections\n",
      "Writing clean text to json\n",
      "--- Downloading 3 of 3 10K filings for 2\n",
      "Extracting 10-K\n",
      "Parsing relevant sections\n",
      "Writing clean text to json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
